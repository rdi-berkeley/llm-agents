---
layout: default
title: "CS294/194-196 Large Language Model Agents"
permalink: /f24
redirect_from:
 - /
---

### Prospective Students

- ***Students interested in the course should first try enrolling in the course in CalCentral. The class number for CS194-196 is 32306. The class number for CS294-196 is 32304. Please join the waitlist if the class is full.***
- ***We plan to expand the class size to allow more students to join. Please fill in the <a href="https://forms.gle/8sHgNLQm44G9yLRA8">signup form</a> if you are on the waitlist or can't get added to the waitlist. You will receive an email notification around the beginning of the fall semester if you are allowed in.***
- ***<span style="color:red">Do not email course staff or TAs. Please use [Edstem](https://edstem.org/us/join/Mmkzqx) for any questions. For private matters, post a private question on Edstem and make sure it is visable to all teaching staff.</span>***

## Course Staff

<table>
<tbody>
<tr>
<td>Instructor</td>
<td>(Guest) Co-instructor</td>
</tr>
<tr>
<td><img src="assets/dawn-berkeley.jpg" height=200/></td>
<td><img src="assets/XinyunChen.jpg" height=200/></td>
</tr>
<tr>
<td><a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></td>
<td>Xinyun Chen</td>
<tr>
<td>Professor, UC Berkeley</td>
<td>Research Scientist, Google DeepMind</td>
</tr>
</tr>
</tbody>
</table>

GSIs: Alex Pan & Sehoon Kim

Readers: Tara Pande & Ashwin Dara

## Class Time and Location

Lecture: 3-5pm PT Monday at Latimer 120

## Course Description

Large language models (LLMs) have revolutionized a wide range of domains. In particular, LLMs have been developed as agents to interact with the world and handle various tasks. With the continuous advancement of LLM techniques, LLM agents are set to be the upcoming breakthrough in AI, and they are going to transform the future of our daily life with the support of intelligent task automation and personalization. In this course, we will first discuss fundamental concepts that are essential for LLM agents, including the foundation of LLMs, essential LLM abilities required for task automation, as well as infrastructures for agent development. We will also cover representative agent applications, including code generation, robotics, web automation, medical applications, and scientific discovery. Meanwhile, we will discuss limitations and potential risks of current LLM agents, and share insights into directions for further improvement. Specifically, this course will include the following topics:
- Foundation of LLMs
- Reasoning
- Planning, tool use
- LLM agent infrastructure
- Retrieval-augmented generation
- Code generation, data science
- Multimodal agents, robotics
- Evaluation and benchmarking on agent applications
- Privacy, safety and ethics
- Human-agent interaction, personalization, alignment
- Multi-agent collaboration

## Syllabus

| Date   | Guest Lecture | Readings <br> (due Sunday 11:59pm before lecture on Gradescope) | 
|--------|-------|-------|
| Sept 9 | **LLM Reasoning** <br> Denny Zhou, Google DeepMind | - [Chain-of-Thought Reasoning Without Prompting](https://arxiv.org/abs/2402.10200) <br> - [LLMs Cannot Self-Correct Reasoning Yet](https://arxiv.org/abs/2310.01798) <br> - [Premise Order Matters in Reasoning with LLMs](https://arxiv.org/abs/2402.08939) <br> - [Chain-of-Thought Transformers Solve Inherently Serial Problems](https://arxiv.org/abs/2402.12875) <br> *All readings are optional this week.* |   
| Sept 16 | **LLM agents: brief history and overview** <br> Shunyu Yao, OpenAI | - [WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents](https://arxiv.org/abs/2207.01206) <br> - [ReAct: Synergizing Reasoning and Acting in Language Models.](https://arxiv.org/abs/2210.03629)  |          
| Sept 23 | **Introduction to Agentic AI and AutoGen** <br> Chi Wang, AutoGen-AI <br> **The Future of Knowledge Assistants** <br> Jerry Liu, LlamaIndex |  |          
| Sept 30 | **Trends of Generative AI with Enterprises, Key blocks to build successful agents** <br> Burak Gokturk, Google |  |          
| Oct 7 | **Compound AI Systems & the DSPy Framework** <br> Omar Khattab, Databricks |  |          
| Oct 14 | **Agents for Software Development** <br> Graham Neubig, Carnegie Mellon University |  |          
| Oct 21 | **Agent for Workflow Applications** <br> Nicolas Chapados, ServiceNow |  |          
| Oct 28 | **Stronger Together: Marrying Neural Networks with Traditional Symbolic Decision-Making** <br> Yuandong Tian, Meta AI (FAIR) |  |          
| Nov 4 | **Foundation Agent** <br> Jim Fan, NVIDIA |  |          
| Nov 11 | **No Class - Veteran's Day** |          |          
| Nov 18 | **Cybersecurity, agents, and open-source** <br> Percy Liang, Stanford University |  |          
| Nov 25 | **LLM Agent Safety** <br> Dawn Song, UC Berkeley |  |          
| Dec 2 | **TBA** <br> Ben Mann, Anthropic |  |   


## Enrollment and Grading

- ***Prerequisite:*** **Students are strongly encouraged to have had experience and basic understanding of Machine Learning and Deep Learning before taking this class, e.g., have taken courses such as CS182, CS188, and CS189.**

***Please fill out the <a href="https://forms.gle/8sHgNLQm44G9yLRA8">signup form</a> if you are on the waitlist or can't get added to the waitlist.***

This is a variable-unit course.
All enrolled students are expected to participate in lectures in person and complete weekly reading summaries related to the course content.
Students enrolling in one unit are expected to submit an article that summarizes one of the lectures.
Students enrolling in more than one unit are expected to submit a lab assignment and a project instead of the article.
The project of students enrolling in 2 units should have a written report, which can be a survey in a certain area related to LLMs.
The project of students enrolling in 3 units should also have an implementation (coding) component that programmatically interacts with LLMs, and the project of students enrolling in 4 units should have a very significant implementation component with the potential for either real world impacts or intellectual contributions.
The grade breakdowns for students enrolled in different units are the following:

|                              | 1 unit | 2 units | 3/4 units |
|------------------------------|--------|---------|-----------|
| Participation                | 45%    | 20%     | 10%       |
| Reading Summaries & Q/A      | 10%    | 4%     | 2%       |
| Article                      | 45%    |         |           |
| Lab                          |        | 16%     | 8%       |
| Project                      |        |         |           |
| &nbsp;&nbsp;*Proposal*       |        | 10%     | 10%       |
| &nbsp;&nbsp;*Milestone 1*      |        | 10%     | 10%       |
| &nbsp;&nbsp;*Milestone 2*      |        | 10%     | 10%       |
| &nbsp;&nbsp;*Presentation*   |        | 15%     | 15%       |
| &nbsp;&nbsp;*Report*         |        | 15%     | 15%       |
| &nbsp;&nbsp;*Implementation* |        |         | 20%       |

## Lab and Project Timeline

|                         | Released | Due    |
|-------------------------|----------|--------|
| Project group formation | 9/9      | 9/16    |
| Project proposal        |  9/16     | 9/30    |
| Lab                     |  9/23     |  10/7   |
| Project milestone #1    |  10/8     |  10/21   |
| Project milestone #2    |  10/29     |  11/18   |
| Project final presentation    |  11/19     | 12/12    |
| Project final report    |  11/19     | 12/12    |

## Office Hours

- Alex: 5-6pm on Mondays on [Zoom](https://berkeley.zoom.us/j/2012565201)
- Sehoon: 10-11am on Tuesdays on [Zoom](https://berkeley.zoom.us/j/5705498591)
